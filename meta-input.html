<!doctype html>
<html lang="en">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

    <link href="css/style.css" rel="stylesheet">

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-145676546-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'UA-145676546-1');
    </script>

    <meta name=”robots” content=”noindex”>

    <title>New Input Methods for AR/VR - Meta</title>
</head>

<body>

    <div class="container-fluid px-md-5 m-top-ss sticky-top">
        <div class="row gx-1">
            <div class="col-3">
                <h2 class="menu-a text-left"><a href="index.html"><img src="svg/back-arrowsvg.svg" class="back-arrow">Work</a></h2>
            </div>
            <div class="col-6">
                <h2 class="menu-a text-center"><a href="index.html">Ricardo Saavedra</a></h2>
            </div>
            <div class="col-3">
                <h2 class="menu-a text-end"><a href="about.html">About</a></h2>
            </div>
        </div>
    </div>

    <div class="container-fluid px-md-5">
        <div class="row gx-md-5 m-top-xl m-bottom-xl">
            <div class="col-md-12">
                <h1 class="title1 main text-lg-center">Quest OS</h1>
            </div>
            <div class="col-md-7 offset-md-5">
                <h2 class="title2 no-m-bottom">Building the next generation of productivity in AR on the new Quest Pro</h2>
            </div>
        </div>
    </div>

    <div class="container-fluid p-0">
        <div class="row g-0 ">
            <div class="col-md-12">
                <img src="img/meta-input/input-horizontal.jpg" class="img-fluid">

            </div>
        </div>
    </div>


    <div class="container-fluid px-md-5">
        <div class="row gx-sm-5 m-top-md">
            <div class="col-lg-6">
                <p class="text1">Horizon Workrooms is an application part of the Work Metaverse experiences. It is designed to allow users to work in immersive spaces and to mirror their computers in VR/VR to enhance their productivity.</p>
            </div>
            <div class="col-lg-6">
                <div class="row g-0">
                    <div class="col-4 top-border">
                        <p class="text2 bold">Role</p>
                    </div>

                    <div class="col-8 top-border">
                        <p class="text2 bold">Senior Product Designer (IC)</p>
                    </div>
                </div>

                <div class="row g-0">
                    <div class="col-4 top-border">
                        <p class="text2 bold">Challenge</p>
                    </div>

                    <div class="col-8 top-border">
                        <p class="text2 bold">To bring the vision for work in the Metaverse to the present by developing new interface paradigms that enable knowledge workers to leverage AR/VR for new productivity use cases</p>
                    </div>
                </div>

                <div class="row g-0">
                    <div class="col-4 top-border">
                        <p class="text2 bold">Contributions</p>
                    </div>

                    <div class="col-8 top-border">
                        <p class="text2 bold">Researched and developed new input methods for VR to improve comfort, aid adoption, and increase satisfaction for users across all VR/AR use cases</p>
                        <p class="text2 bold">Worked to abstract complexity inherent in spatial computing to create new features and ways of working in VR that are easy to use and desirable for knowledge work users</p>
                        <p class="text2 bold">Contributed to large redesign application projects to include new, more flexible ways to work in augmented reality</p>
                        <p class="text2 bold">Worked with researchers and PMs to identify gaps and opportunities and communicated them to other teams at Meta</p>
                    </div>
                </div>

                <div class="row g-0">
                    <div class="col-4 top-border">
                        <p class="text2 bold">Impact</p>
                    </div>

                    <div class="col-8 top-border">
                        <p class="text2 bold">Contributed to Workrooms redesign to create an AR model that is more fluid and flexible to many use cases</p>
                        <p class="text2 bold">Worked on designing new AR interaction patterns shipped with the new Quest Pro</p>
                        <p class="text2 bold">Developed concepts from early-stage ideas to concrete hardware/software specs, directly influencing Meta's hardware roadmap</p>
                    </div>
                </div>
            </div>

            <div class="row gx-md-5 m-top-xxl">
                <div class="col-lg-6">
                    <h1 class="title1">The Metaverse Vision
                        <p class="text1 no-m-top">Key Challenges</p>

                    </h1>
                </div>
                <div class="col-lg-6">
                    <p class="text2">The vision for work in the "Metaverse" shows that working in VR and AR is better than using today's computing devices. You wear a headset because it allows you to overlay your screens and digital artifacts on top of your world, and you can have meetings with your co-workers in your own home or office in much more immersive ways. It's hard to disagree with this long-term vision, but its resolution needs to be higher to inspire short-term execution.</p>
                </div>
                <div class="col-lg-9 offset-lg-3 pb-4">
                    <iframe class="video-youtube" src="https://www.youtube.com/embed/5_bVkbG1ZCo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                </div>
                <div class="col-lg-6 offset-lg-6">
                    <div class="col top-border">
                        <!-- BODY TITLE -->
                        <p class="text2 bold">The gap between the vision and the present</p>
                        <p class="text2">While there's much speculation about the potential of VR and AR technologies to revolutionize how we work, think, and collaborate, the current design implementation and end-to-end user experience leave much to desire. When observed closely, today's offerings and design implementations are light years away from this vision. Key narrative points such as "VR/AR replacing your computer monitor" or "I can be much more productive in VR" it misses the granularity required to design good experiences for XR. For example, pinching with your fingers and adjusting the side of a window from a distance looks good in a video, but it's not practical in reality. It doesn't provide a good experience because you need to be extremely precise, and the gesture becomes overly exhausting after an 8hr work day. The journey of new Quest users begins with excitement, then moves to low motivation to finally abandon within two/three weeks of buying a device.</p>
                    </div>
                </div>

                <div class="col-lg-6 offset-lg-6">
                    <div class="col top-border">
                        <!-- BODY TITLE -->
                        <p class="text2 bold">The hardware gap</p>
                        <p class="text2">It's easier to talk about the experience of using VR/AR when considering the role of hardware. Unlike laptops, VR devices impact how you feel inside an experience. Aspects such as framerate and pixel resolution can change your perception of the entire experience. Weight, tracking, and battery affect how users perceive their interaction with XR applications. On the computing side, standalone devices are limited and will continue to be for a long time. There aren't simple solutions to this problem in the near term. It's easy to see this limitation as an impairment, but it's also possible to frame it as a creative constraint for Design. For example, If hardware is limited, then the choice regarding What should be even more intentional. In other words, what experiences should designers focus on that create real user value? What features and use cases can be significant to justify owning VR hardware? Assuming that some friction points will remain, how do designers create value to aid the adoption of VR in the short term?</p>
                    </div>
                </div>

                <div class="col-lg-6 offset-lg-6">
                    <div class="col top-border">
                        <!-- BODY TITLE -->
                        <p class="text2 bold">The Design gap</p>
                        <p class="text2">The biggest challenge for VR isn't the hardware per se but the ability to rethink how we do interaction design in this new paradigm. Looking at how the Quest OS, it's easy to see old patterns finding their way into VR without much concern regarding potential alternatives and how the end experience will feel for users. There are a few reasons for this. First, VR development originated from games and immersive environments. You see these choices reflected in the selection of hardware. VR controllers, for example, are joysticks, not touchpads. Because of this, the entire OS reflects simple design choices made years ago, such as point-and-click input methods (either with the hand or controller).</p>

                        <p class="text2">The design gap is not Meta specific and torments every VR manufacturer. Instead, this design gap is a universal challenge that marks the end of an era entirely built on the WIMP (Windows, Icons, Menus, Pointer) paradigm. WIMP has been the predominant interface paradigm from the 80s to today. The same model was adapted and improved for touch devices such as the iPad/iPhone, but while the UX seems new, the model remains essentially the same. It's expectable that the first generation of OS would extend this model. Still, almost ten years later, its limitations can be felt by every user, be they gamers or knowledge workers.</p>
                    </div>
                </div>

                <div class="col-lg-9 offset-lg-3">
                    <p class="text1">If the experience of using VR is marginally better than existing computing paradigms, VR's friction won't justify the switch. If the way we interact in VR is cumbersome and full of micro-frictions, VR offerings will need to be substantially better than existing alternatives.</p>
                </div>

                <div class="col-lg-6 offset-lg-6">
                    <p class="text2">The dilemma above summarises the intricacies and interdependencies between Design and hardware when designing for XR. Different device manufacturers might focus on reducing friction or improving users' value, but VR adoption will only happen when both are in place.</p>

                    <p class="text2">Due to the heavy hardware limitation and slow adoption from serious games, Meta is course-correcting and adjusting its original strategy. Instead of trying to place VR as a gaming device, it now focuses on VR for productivity use cases. The Quest Pro was presented as an extension of your workspace and was designed for solo work and social interactions in immersive spaces. The entire hardware form factor and specs focused on giving you the best possible device for this new immersive paradigm called "Metaverse."</p>
                </div>


            </div>

            <div class="row gx-md-5 m-top-xxl m-bottom-xxl">
                <div class="col-lg-6">
                    <h1 class="title1">Contributions and Projects</h1>
                </div>
                <div class="col-lg-6">
                    <p class="text2">As a design leader and individual contributor at Meta, I focused on tangible outcomes I could influence in the short term. For example, I focused on evaluating existing implementations and observing user behavior across different countries to inspire me to focus on the right problems to solve. Early adopters and users who escape the average productivity user are always more valuable than observing users at the center of the bell curve. For example, when dealing with the limitations of housing areas, many users in Japan are already using Horizon Workrooms as their office, spending more than 5hrs a day. These users have developed many hacks to extend battery life and overcome today's limitations to create an ideal experience in the present.</p>
                    <p class="text2">From observations such as these, I developed a working hypothesis that saw general VR adoption as long-term. Still, it was possible to triple adoption in the short term by removing major friction points. My perspective on solving these problems focused mainly on Design and off-the-shelf engineering solutions. They asked hard questions about alternative ways to structure the behavior or applications in VR, but they were also hyper-realistic and pragmatic to implement.</p>
                </div>

                <div class="col-lg-6 offset-lg-6">
                    <div class="col top-border">
                        <!-- BODY TITLE -->
                        <p class="text2 bold">Solving interaction and usability problems</p>
                        <p class="text2">There are two main ways to solve usability/design problems. The first approach focuses on iterating on a solution to improve its comprehension or ease of use. The second focuses on using existing user problems as a starting point to rethink how fundamental aspects of how things work. For example, it's possible to make buttons bigger to make far-field interactions with the controller easier, but this usability problem can also help question existing input methods altogether. During my time at Meta, I focused on thinking about problems systematically because of the impact such components could have on the end-to-end user experience.</p>
                    </div>
                </div>
            </div>

            <div class="row gx-md-5 m-top-xxl m-bottom-xxl">
                <div class="col-lg-6">
                    <h1 class="title1">Exploring New Input Methods for XR</h1>
                </div>
                <div class="col-lg-6">
                    <p class="text2">For example, I explored the potential of envisioning new input methods in VR focused on allowing users to transpose their experiences with phones and tablets to VR much more quickly than existing hand-held controllers. These concepts focused on existing mental models users already have about how things should work while creating new opportunities for the entire Quest ecosystem. I concentrated on usability-focused metrics such as ease of use and precision and user satisfaction, playfulness, and flow, combined with more loose emotional needs such as predictability to validate solutions. </p>
                    <p class="text2">While exploring solutions, I paid great attention to the growing AR/VR divide. Today, when users transition from VR to AR, it's expected that virtual screens that work well in VR don't sit well with overlaid onto their physical environment. Similarly, you can be immersed in VR and accidentally bump into a hot cup of coffee you forgot on your table. Again, users often mentioned that the immersion afforded by VR kept them from using VR altogether because it would keep them away from their world of notifications and quick access to applications they need with them. Problems such as these prevent users from genuinely taking advantage of this new computing paradigm.</p>
                </div>

                <div class="col-lg-6 offset-lg-6">
                    <div class="col top-border">
                        <!-- BODY TITLE -->
                        <p class="text2 bold">Solving interaction and usability problems</p>
                        <p class="text2">There are two main ways to solve usability/design problems. The first approach focuses on iterating on a solution to improve its comprehension or ease of use. The second focuses on using existing user problems as a starting point to rethink how fundamental aspects of how things work. For example, it's possible to make buttons bigger to make far-field interactions with the controller easier, but this usability problem can also help question existing input methods altogether. During my time at Meta, I focused on thinking about problems systematically because of the impact such components could have on the end-to-end user experience.</p>
                    </div>
                </div>

                <div class="col-lg-9 offset-lg-3">
                    <p class="text1">To solve these problems, I designed solutions and methods allowing users to quickly navigate from VR to AR while maintaining a 1:1 spatial mapping from virtual to personal physical spaces.</p>
                </div>

                <div class="col-lg-6 offset-lg-6">
                    <p class="text2">To solve these problems, I designed solutions and methods allowing users to quickly navigate from VR to AR while maintaining a 1:1 spatial mapping from virtual to personal physical spaces. These solutions ranged from active objects that worked to anchor interactions in space. I focused both on spatial awareness and tactical and playful interactions that allowed users to quickly access content from other applications in the Quest Ecosystem to give them complete control of their experience.</p>
                </div>

                <div class="col-lg-6 offset-lg-6">
                    <p class="text2">If AR is to be useful and adopted, it also needs to be tactile and easy to grasp. We love our phones and computers because they are part of us; we can feel and move them. Similarly, we need easy and intuitive ways to control AR augmentations in meaningful ways. Because AR augmentations can exist on any surface and quickly lead to cognitive overload, users need to remain in control and not feel overwhelmed. This vision of AR is inherently different from what AR glasses seek to propose. AR glasses are HUD (heads-up displays) and don't often focus on ambient or spatially oriented interfaces.</p>
                </div>
            </div>

            <div class="row gx-md-5 m-top-xxl m-bottom-xxl">
                <div class="col-lg-6">
                    <h1 class="title1">Product Impact</h1>
                </div>
                <div class="col-lg-6">
                    <p class="text2">The result of this work has influenced a new generation of applications and features yet to be released by Workrooms. The result is still far from the long-term vision, but it helped the company to take tangible steps toward a design implementation that is valuable and desirable for today's and tomorrow's VR users.</p>
                </div>
            </div>
        </div>
    </div>

    <!-- Optional JavaScript; choose one of the two! -->

    <!-- Option 1: Bootstrap Bundle with Popper -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
</body>

</html>