<!doctype html>
<html lang="en">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

    <link href="css/style.css" rel="stylesheet">

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-145676546-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'UA-145676546-1');
    </script>

    <meta name=”robots” content=”noindex”>

    <title>New Input Methods for AR/VR - Meta</title>
</head>

<body>

    <div class="container-fluid px-md-5 m-top-ss sticky-top">
        <div class="row gx-1">
            <div class="col-3">
                <h2 class="menu-a text-left"><a href="index.html"><img src="svg/back-arrowsvg.svg" class="back-arrow">Work</a></h2>
            </div>
            <div class="col-6">
                <h2 class="menu-a text-center"><a href="index.html">Ricardo Saavedra</a></h2>
            </div>
            <div class="col-3">
                <h2 class="menu-a text-end"><a href="about.html">About</a></h2>
            </div>
        </div>
    </div>

    <div class="container-fluid px-md-5">
        <div class="row gx-md-5 m-top-xl m-bottom-xl">
            <div class="col-md-12">
                <h1 class="title1 main text-lg-center">Quest OS</h1>
            </div>
            <div class="col-md-7 offset-md-5">
                <h2 class="title2 no-m-bottom">Exploring new input methods for XR to increae adoption and easy-of-use</h2>
            </div>
        </div>
    </div>

    <div class="container-fluid p-0">
        <div class="row g-0 ">
            <div class="col-md-12">
                <img src="img/meta-input/input-horizontal.jpg" class="img-fluid">

            </div>
        </div>
    </div>


    <div class="container-fluid px-md-5">
        <div class="row gx-sm-5 m-top-md">
            <div class="col-lg-6">
                <p class="text1">Horizon Workrooms is an application part of the Work Metaverse experiences. It is designed to allow users to work in immersive spaces and to mirror their computers in VR/VR to enhance their productivity.</p>
            </div>
            <div class="col-lg-6">
                <div class="row g-0">
                    <div class="col-4 top-border">
                        <p class="text2 bold">Role</p>
                    </div>

                    <div class="col-8 top-border">
                        <p class="text2 bold">Senior Product Designer (IC)</p>
                    </div>
                </div>

                <div class="row g-0">
                    <div class="col-4 top-border">
                        <p class="text2 bold">Challenge</p>
                    </div>

                    <div class="col-8 top-border">
                        <p class="text2 bold">To bring the vision for work in the Metaverse to the present by developing new interface paradigms that enable knowledge workers to leverage AR/VR for new productivity use cases</p>
                    </div>
                </div>

                <div class="row g-0">
                    <div class="col-4 top-border">
                        <p class="text2 bold">Contributions</p>
                    </div>

                    <div class="col-8 top-border">
                        <p class="text2 bold">Researched and developed new input methods for VR to improve comfort, aid adoption, and increase satisfaction for users across all VR/AR use cases</p>
                        <p class="text2 bold">Worked to abstract complexity inherent in spatial computing to create new features and ways of working in VR that are easy to use and desirable for knowledge work users</p>
                        <p class="text2 bold">Contributed to large redesign application projects to include new, more flexible ways to work in augmented reality</p>
                        <p class="text2 bold">Worked with researchers and PMs to identify gaps and opportunities and communicated them to other teams at Meta</p>
                    </div>
                </div>

                <div class="row g-0">
                    <div class="col-4 top-border">
                        <p class="text2 bold">Impact</p>
                    </div>

                    <div class="col-8 top-border">
                        <p class="text2 bold">Developed concepts from early-stage ideas to concrete hardware/software specs, directly influencing Meta's hardware roadmap</p>
                    </div>
                </div>
            </div>


            <div class="row gx-md-5 m-top-xxl">
                <div class="col-lg-6">
                    <h1 class="title1">Exploring New Input Methods for XR</h1>
                </div>
                <div class="col-lg-6">
                    <p class="text2">Disclaimer: The images and content only exemplify the nature of my work. To comply with NDA requirements, I composed new images to illustrate the concepts without disclosing any specific project information.</p>
                    
                    <p class="text2">While working with a special team at Reality Labs dedicated to developing new AR-based concepts and products, I explored new hardware concepts to improve usability and flexibility in VR.</p>
                    
                    <p class="text2">I worked to envision alternative designs that were developed specifically for the paradigm of spatial computing. After gathering many user insights regarding VR us, I concluded that today's controllers left many UX challenges unsolved.</p>
                    
                    <p class="text2">A critical condition for the wider VR adoption lies in allowing users to transpose their experiences with phones and tablets to VR much more quickly without high learning curves. Therefore, I chose to focus on concepts that leverage existing mental models while creating new opportunities for the Quest Ecosystem. More specifically, I concentrated on usability-focused metrics such as ease of use and precision, user satisfaction, playfulness, and user flow.</p>
                </div>

                
                
                <div class="col-lg-6 offset-lg-6">
                </div>

                <div class="col-lg-9 offset-lg-3">
                    <p class="text1">Instead of measuring the success of new input methods in existing applications (e.g., games, immersive worlds), I was focused on unlocking new experiences and applications that are extremely hard to use today.</p>
                </div>

                <div class="col-lg-6 offset-lg-6">
                    <p class="text2">While exploring solutions, I paid great attention to the growing AR/VR divide. Today, when users transition from VR to AR, it's expected that virtual screens that work well in VR don't sit well with overlaid onto their physical environment. Similarly, you can be immersed in VR and accidentally bump into a hot cup of coffee you forgot on your table. Again, users often mentioned that the immersion afforded by VR kept them from using VR altogether because it would keep them away from their world of notifications and quick access to applications they need with them. Problems such as these prevent users from genuinely taking advantage of this new computing paradigm.</p>
                </div>
                
                <div class="col-lg-12">
                <img src="img/meta-input/weather.png" class="img-fluid body">
            </div>

                <div class="col-lg-6 offset-lg-6 m-top-sm">
                    <p class="text2">To solve these problems, I designed solutions and methods allowing users to quickly navigate from VR to AR while maintaining a 1:1 spatial mapping from virtual to personal physical spaces. These solutions ranged from active objects that worked to anchor interactions in space. I focused both on spatial awareness and tactical and playful interactions that allowed users to quickly access content from other applications in the Quest Ecosystem to give them complete control of their experience.</p>
                    
                    <p class="text2">If AR is to be adopted, it must be tactile and easy to grasp. We love our phones and computers because they are part of us; we can feel and move them. Similarly, we need easy and intuitive ways to control AR augmentations in meaningful ways. Because AR augmentations can exist on any surface and quickly lead to cognitive overload, users need to remain in control and not feel overwhelmed. This vision of AR is inherently different from what AR glasses seek to propose. AR glasses are HUD (heads-up displays) and don't often focus on ambient or spatially oriented interfaces.</p>
                </div>
                
                <div class="col-lg-12">
                <img src="img/meta-input/extended-ui.png" class="img-fluid body">
            </div>
            </div>
            
            

            <div class="row gx-md-5 m-top-xxl m-bottom-xxl">
                <div class="col-lg-6">
                    <h1 class="title1">Product Impact</h1>
                </div>
                <div class="col-lg-6">
                    <p class="text2">The result of this work has impacted Meta's hardware roadmap, and other hardware OS teams in the organization received it well.</p>
                </div>
            </div>
        </div>
    </div>

    <!-- Optional JavaScript; choose one of the two! -->

    <!-- Option 1: Bootstrap Bundle with Popper -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
</body>

</html>